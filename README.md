
# Purpose:


A startup called **Sparkify** wants to analyze the data they've been collecting on songs and user activity on their new music streaming app. The analytics team is particularly interested in understanding what songs, users are listening to. 

Currently, they don't have an easy way to query their data, which resides in a directory of JSON logs on user activity on the app, as well as a directory with JSON metadata on the songs in their app. 

The purpose of this project is to extract data from the json files and store it in the database tables. This would help the analytics team to query and analyze the data.

## Datasets:


The following two datasets are used:

**Song dataset**: 
> Dataset contains metadata about a song and the artist of that song. Each file is in JSON format. The files are partitioned by the first three letters of each song's track ID.
>> *Location*: data\song_data
>> *Example*:
>>> Path of a file: data\song_data\A\A\A\TRAAAAW128F428D538.json
>>> {"num_songs": 1, "artist_id": "ARD7TVE1187B99BFB1", "artist_latitude": null, "artist_longitude": null, "artist_location": "California - LA", "artist_name": "Casual", "song_id":  "SOMZWCG12A8C13C480", "title": "I Didn't Mean To", "duration": 218.93179, "year": 0}

**Log Dataset**: 
> Dataset consists of log files generated by the simulator based on the songs in the Song dataset. Each file is in JSON format. The files are partitioned by year and month.
>> *Location*: data\log_data
>> *Example*:
>>> Path of a file: data\log_data\2018\11\2018-11-01-events.json
>>> {"artist":null,"auth":"Logged In","firstName":"Walter","gender":"M","itemInSession":0,"lastName":"Frye","length":null,"level":"free","location":"San Francisco-Oakland-Hayward, CA","method":"GET","page":"Home","registration":1540919166796.0,"sessionId":38,"song":null,"status":200,"ts":1541105830796,"userAgent":"\"Mozilla\/5.0 (Macintosh; Intel Mac OS X 10_9_4) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/36.0.1985.143 Safari\/537.36\"","userId":"39"}
>>> .
>>> .
>>> .
>>> {"artist":"Survivor","auth":"Logged In","firstName":"Jayden","gender":"M","itemInSession":0,"lastName":"Fox","length":245.36771,"level":"free","location":"New Orleans-Metairie, LA","method":"PUT","page":"NextSong","registration":1541033612796.0,"sessionId":100,"song":"Eye Of The Tiger","status":200,"ts":1541110994796,"userAgent":"\"Mozilla\/5.0 (Windows NT 6.3; WOW64) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/36.0.1985.143 Safari\/537.36\"","userId":"101"}

## Execution steps:


1. First, run create_tables (**command**: `python create_tables.py`) file in the terminal. This file will drop tables (songplays, users, songs, artists, time) if already exists in the workspace or the file will create tables for inserting records.
2. Next, run etl (**command**: `python etl.py`) file in the terminal. This file will process the JSON files and insert the data to all the tables based on the requirements.